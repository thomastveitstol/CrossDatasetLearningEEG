run_baseline: true
selected_target: &selected_target sex

Shared Dataset Details:
  num_time_steps: &num_time_steps null
  time_series_start: &time_series_start null

SubjectSplit:
  name: SplitOnDataset
  kwargs:
    seed: 42  # todo: should we fix the seed?

SubGroups:
  verbose: false
  sub_groups:
    dataset_name:  # todo: don't hardcode like this
      [ rockhill, miltiadous, hatlestad_hall, yulin_wang, cau_eeg ]

Datasets:
  rockhill:
    num_subjects: 31
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  miltiadous:
    num_subjects: 88
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  hatlestad_hall:
    num_subjects: 111
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  yulin_wang:
    num_subjects: 60
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  # ous:
  #   num_subjects: 1000
  #   num_time_steps: *num_time_steps
  #   time_series_start: *time_series_start
  cau_eeg:
    num_subjects: 1379
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age ]

Targets:
  age:
    main_metric: [ mae, mse, pearson_r, spearman_rho, r2_score ]
    prediction_activation_function: null
    Loss:
      loss:
        dist: uniform_discrete
        kwargs:
          domain: [ MSELoss, L1Loss ]
      loss_kwargs: { }  # reduction parameter will be set to 'none' or 'mean', depending on the sampled loss weighter
      weighter: # todo: weighter and the kwargs must be sampled together
        dist: uniform_discrete
        kwargs:
          domain: [ null, SamplePowerWeighter ]
      weighter_kwargs: # Dataset sizes will be added during runtime
        weight_power:
          dist: uniform
          kwargs:
            a: 0
            b: 1
    metrics: regression
    scaler:
      target:
        dist: uniform_discrete
        kwargs:
          domain:
            - name: ZNormalisation
              kwargs: { }
  sex:
    main_metric: [ auc ]
    prediction_activation_function: sigmoid
    Loss:
      loss:
        dist: uniform_discrete
        kwargs:
          domain: [ BCEWithLogitsLoss ]
      loss_kwargs: { }  # reduction parameter will be set to 'none' or 'mean', depending on the sampled loss weighter
      weighter: # todo: weighter and the kwargs must be sampled together
        dist: uniform_discrete
        kwargs:
          domain: [ null, SamplePowerWeighter ]
      weighter_kwargs: # Dataset sizes will be added during runtime
        weight_power:
          dist: uniform
          kwargs:
            a: 0
            b: 1
    metrics: classification
    scaler:
      target:
        dist: uniform_discrete
        kwargs:
          domain:
            - name: NoScaler
              kwargs: { }

Training:
  # Fixed hyperparameters
  batch_size: 16
  num_epochs: 10
  verbose: true
  val_split: 0.2
  target: *selected_target
  continuous_testing: true
  # metrics: regression
  # Varied hyperparameters
  learning_rate:
    dist: log_uniform
    kwargs:
      base: 10
      a: -5
      b: -2
  beta_1:
    dist: uniform
    kwargs:
      a: 0.8
      b: 1.0
  beta_2:
    dist: uniform
    kwargs:
      a: 0.8
      b: 1.0
  eps:
    dist: log_uniform
    kwargs:
      base: 10
      a: -10
      b: -6

# -----------------
# Domain discriminator
# -----------------
FCModule: &FCModule
  hidden_units:
    dist: uniform_discrete
    kwargs:
      # domain: [ [], [32], [64], [32, 32], [64, 64], [64, 32] ]  # todo
      domain: [ [], [4, 8], [4, 4], [8, 8] ]

DomainDiscriminator:
  discriminators:
    NoDiscriminator: null
    FCModule: *FCModule
  training:
    Loss:
      loss: CrossEntropyLoss
      loss_kwargs:
        reduction: mean
      weighter: null  # todo: add sample-wise weighting of loss function
      weighter_kwargs: { }
    metrics: multiclass_classification
    lambda:
      dist: log_uniform
      kwargs:
        base: 10
        a: -6
        b: -1


# -----------------
# Methods for handling a varied number of channels
# -----------------
box: &box
  x_min: -0.17
  x_max: 0.17
  y_min: -0.17
  y_max: 0.17

# Pooling methods

num_kernels: &num_kernels
  dist: log_uniform_int
  kwargs:
    base: 10
    a: 2
    b: 3

# todo: consider computing this from the sampling frequency instead
max_receptive_field: &max_receptive_field
  dist: log_uniform_int
  kwargs:
    base: 10
    a: 2
    b: 2.5

MultiCSSharedRocket: &MultiCSSharedRocket
  num_kernels: *num_kernels
  max_receptive_field: *max_receptive_field

MultiMSSharedRocketHeadRegion: &MultiMSSharedRocketHeadRegion
  num_kernels: *num_kernels
  max_receptive_field: *max_receptive_field
  latent_search_features:
    dist: log_uniform_int
    kwargs:
      base: 2
      a: 3  # 2^3 = 8
      b: 7  # 2^8 = 256
  share_search_receiver_modules: [ true, false]
  bias: false

PoolingModules: &PoolingModules
  MultiCSSharedRocket: *MultiCSSharedRocket
  MultiMSSharedRocketHeadRegion: *MultiMSSharedRocketHeadRegion

# Montage splits  todo: update the kwargs
VoronoiSplit: &VoronoiSplit
  channel_systems:
    dist: uniform_discrete
    kwargs:
      domain: [ [ rockhill, miltiadous, hatlestad_hall, yulin_wang, cau_eeg ] ]
  min_nodes: 1  # todo: other values must be implemented
  num_initial_centroids:
    dist: log_uniform_int
    kwargs:
      base: 10
      a: 2
      b: 3
  <<: *box

CentroidPolygons: &CentroidPolygons
  channel_positions:
    dist: uniform_discrete
    kwargs:
      domain: [ [ cau_eeg ] ]
  min_nodes:
    dist: uniform_int
    kwargs:
      a: 1
      b: 6  # not including 6
  k:
    dist: uniform_discrete
    kwargs:
      domain: [[2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3], [2, 3, 2, 3, 2, 3, 2, 3, 2], [4, 3, 2, 3, 4, 3, 2, 3, 4]]

MontageSplits: &MontageSplits
  VoronoiSplit: *VoronoiSplit
  CentroidPolygons: *CentroidPolygons

RegionBasedPooling: &RegionBasedPooling
  num_montage_splits:
    dist: log_uniform_int
    kwargs:
      base: 2
      a: 0  # 2^0 = 1
      b: 4  # 2^5 = 32
  normalise_region_representations:
    dist: uniform_discrete
    kwargs:
      domain: [ true, false ]
  share_all_pooling_modules:
    dist: uniform_discrete
    kwargs:
      domain: [ true, false ]
  num_pooling_modules: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ]  # todo
  use_cmmn_layer : [ true, false ]
  RBPDesign:
    num_designs: 1
    pooling_type: multi_cs
    pooling_module: *PoolingModules
    montage_split: *MontageSplits
    cmmn_kwargs:
      kernel_size:  # todo: what to use here?
        dist: uniform_discrete
        kwargs:
          domain: [ 64, 128, 256, 512, 1024, 2048 ]

# Interpolation
SphericalSplineInterpolation: &SphericalSplineInterpolation [ HatlestadHall, YulinWang ]

Varied Numbers of Channels:
  RegionBasedPooling: *RegionBasedPooling
  # SphericalSplineInterpolation: *SphericalSplineInterpolation


# -----------------
# Deep learning architectures
# TODO: I have to check the hyperparameters, of the braindecode models in particular
# -----------------
InceptionNetwork: &InceptionNetwork
  num_classes: 1
  cnn_units:
    dist: log_uniform_int
    kwargs:
      base: 2
      a: 3  # 2^3 = 8
      b: 8  # 2^8 = 256
  depth:  # todo
    dist: uniform_discrete
    kwargs:
      domain: [ 3, 6, 9, 12, 15, 18 ]

EEGNetv4MTS: &EEGNetv4MTS
  num_classes: 1
  num_time_steps: *num_time_steps
  kernel_length:
    dist: log_uniform_int
    kwargs:
      base: 2
      a: 3
      b: 6

EEGResNetMTS: &EEGResNetMTS
  num_classes: 1
  num_time_steps: *num_time_steps
  n_layers_per_block:
    dist: uniform_discrete
    kwargs:
      domain: [ 2, 3, 4 ]
  first_filter_length:
    dist: uniform_discrete
    kwargs:
      domain: [ 3, 5, 7 ]

ShallowFBCSPNetMTS: &ShallowFBCSPNetMTS  # todo: output dimension have ndim=3
  num_classes: 1
  num_time_steps: *num_time_steps
  n_filters_time:
    dist: uniform_int
    kwargs:
      a: 15
      b: 36  # not including 36
  n_filters_spat:
    dist: uniform_int
    kwargs:
      a: 15
      b: 36  # not including 36

Deep4NetMTS: &Deep4NetMTS
  num_classes: 1
  num_time_steps: *num_time_steps
  n_filters_time:
    dist: uniform_int
    kwargs:
      a: 20
      b: 60
  filter_time_length:
    dist: uniform_int
    kwargs:
      a: 15
      b: 36
  n_filters_spat:
    dist: uniform_int
    kwargs:
      a: 20
      b: 60
  split_first_layer: true  # AttributeError of set to False
  batch_norm: [ true, false ]
  drop_prob:
    dist: uniform
    kwargs:
      a: 0
      b: 0.8
  n_filters_2:
    dist: uniform_int
    kwargs:
      a: 50
      b: 150
  n_filters_3:
    dist: uniform_int
    kwargs:
      a: 50
      b: 150
  n_filters_4:
    dist: uniform_int
    kwargs:
      a: 50
      b: 150
  filter_length_2:
    dist: uniform_int
    kwargs:
      a: 5
      b: 15
  filter_length_3:
    dist: uniform_int
    kwargs:
      a: 5
      b: 15
  filter_length_4:
    dist: uniform_int
    kwargs:
      a: 5
      b: 15

MTS Module:
  InceptionNetwork: *InceptionNetwork
  EEGNetv4MTS: *EEGNetv4MTS
  EEGResNetMTS: *EEGResNetMTS
  # ShallowFBCSPNetMTS: *ShallowFBCSPNetMTS
  Deep4NetMTS: *Deep4NetMTS
