run_baseline: false
cv_method: [ inverted, normal ]
selected_target: &selected_target age

Shared Dataset Details:
  num_time_steps: &num_time_steps null
  time_series_start: &time_series_start null

SubjectSplit:
  name: SplitOnDataset
  kwargs:
    seed: 42  # todo: should we fix the seed?

SubGroups:
  verbose: true
  sub_groups:
    dataset_name:  # todo: don't hardcode like this
      [ Miltiadous, HatlestadHall, YulinWang, MPILemon, TDBrain, CAUEEG ]

LatentFeatureDistribution:
  make_initial_distribution_exploration: false
  colormap: viridis
  distance_measures: [ centroid_l2, average_l2_to_centroid ]

Datasets:
  TDBrain:
    num_subjects: 1273
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  Miltiadous:
    num_subjects: 88
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  HatlestadHall:
    num_subjects: 111
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  YulinWang:
    num_subjects: 60
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  MPILemon:
    num_subjects: 203
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, sex ]
  CAUEEG:
    num_subjects: 1379
    num_time_steps: *num_time_steps
    time_series_start: *time_series_start
    target_availability: [ age, alzheimers ]

Targets:
  age:
    main_metric: [ mae, mse, pearson_r, spearman_rho, r2_score ]
    prediction_activation_function: null
    Loss:
      loss:
        dist: uniform_discrete
        kwargs:
          domain: [ MSELoss, L1Loss ]
      loss_kwargs: { }  # reduction parameter will be set to 'none' or 'mean', depending on the sampled loss weighter
      weighter: # todo: weighter and the kwargs must be sampled together
        dist: uniform_discrete
        kwargs:
          domain: [ null, SamplePowerWeighter ]
      weighter_kwargs: # Dataset sizes will be added during runtime
        weight_power:
          dist: uniform
          kwargs:
            a: 0
            b: 1
    metrics: regression
    scaler:
      target:
        dist: uniform_discrete
        kwargs:
          domain:
            - name: ZNormalisation
              kwargs: { }
  sex:
    main_metric: [ auc ]
    prediction_activation_function: sigmoid
    Loss:
      loss:
        dist: uniform_discrete
        kwargs:
          domain: [ BCEWithLogitsLoss ]
      loss_kwargs: { }  # reduction parameter will be set to 'none' or 'mean', depending on the sampled loss weighter
      weighter: # todo: weighter and the kwargs must be sampled together
        dist: uniform_discrete
        kwargs:
          domain: [ null, SamplePowerWeighter ]
      weighter_kwargs: # Dataset sizes will be added during runtime
        weight_power:
          dist: uniform
          kwargs:
            a: 0
            b: 1
    metrics: classification
    scaler:
      target:
        dist: uniform_discrete
        kwargs:
          domain:
            - name: NoScaler
              kwargs: { }

Training:
  # Fixed hyperparameters
  batch_size: 128
  num_epochs: 50
  verbose: true
  ValSplit:
    name: DatasetBalancedTrainValSplit
    kwargs:
      val_split: 0.2
  target: *selected_target
  continuous_testing: true
  # metrics: regression
  # Varied hyperparameters
  learning_rate:
    dist: log_uniform
    kwargs:
      base: 10
      a: -5
      b: -3
  beta_1:
    dist: uniform
    kwargs:
      a: 0.8
      b: 1.0
  beta_2:
    dist: uniform
    kwargs:
      a: 0.9
      b: 1.0
  eps:
    dist: log_uniform
    kwargs:
      base: 10
      a: -10
      b: -6

# -----------------
# Domain discriminator
# -----------------
FCModule: &FCModule
  hidden_units:
    dist: uniform_discrete
    kwargs:
      # domain: [ [], [32], [64], [32, 32], [64, 64], [64, 32] ]  # todo
      domain: [ [4], [8], [8, 4], [4, 4], [8, 8] ]

DomainDiscriminator:
  discriminators:
    NoDiscriminator: null
    FCModule: *FCModule
  training:
    Loss:
      loss: CrossEntropyLoss
      loss_kwargs:
        reduction: mean
      weighter: null  # todo: add sample-wise weighting of loss function
      weighter_kwargs: { }
    metrics: multiclass_classification
    lambda:
      dist: log_uniform
      kwargs:
        base: 10
        a: -6
        b: -1

CMMN:
  use_cmmn_layer: [ true, false ]
  kwargs:
      kernel_size:  # todo: what to use here?
        dist: uniform_discrete
        kwargs:
          domain: [ 64, 128, 256, 512, 1024 ]


# -----------------
# Methods for handling a varied number of channels
# -----------------
box: &box
  x_min: -0.17
  x_max: 0.17
  y_min: -0.17
  y_max: 0.17

# Pooling methods

num_kernels: &num_kernels
  dist: log_uniform_int
  kwargs:
    base: 10
    a: 2
    b: 3

# todo: consider computing this from the sampling frequency instead
max_receptive_field: &max_receptive_field
  dist: log_uniform_int
  kwargs:
    base: 10
    a: 2
    b: 2.5

MultiMSMean: &MultiMSMean {}

MultiCSSharedRocket: &MultiCSSharedRocket
  num_kernels: *num_kernels
  max_receptive_field: *max_receptive_field

MultiMSSharedRocketHeadRegion: &MultiMSSharedRocketHeadRegion
  num_kernels: *num_kernels
  max_receptive_field: *max_receptive_field
  latent_search_features:
    dist: log_uniform_int
    kwargs:
      base: 2
      a: 3  # 2^3 = 8
      b: 7  # 2^7 = 128
  share_search_receiver_modules: [ true, false]
  bias: false

PoolingModules: &PoolingModules
  MultiMSMean: *MultiMSMean
  MultiCSSharedRocket: *MultiCSSharedRocket
  MultiMSSharedRocketHeadRegion: *MultiMSSharedRocketHeadRegion

# Montage splits  todo: update the kwargs
VoronoiSplit:  # &VoronoiSplit
  channel_systems:
    dist: uniform_discrete
    kwargs:
      domain: [ [ Miltiadous, HatlestadHall, YulinWang, MPILemon, TDBrain, CAUEEG ] ]
  min_nodes: 1  # todo: other values must be implemented
  num_initial_centroids:
    dist: log_uniform_int
    kwargs:
      base: 10
      a: 2
      b: 3
  <<: *box

CentroidPolygons: &CentroidPolygons
  channel_positions:
    dist: uniform_discrete
    kwargs:
      domain: [ [ Miltiadous ] ]  # todo
  min_nodes:
    dist: uniform_int
    kwargs:
      a: 1
      b: 6  # not including 6
  k:
    dist: uniform_discrete
    kwargs:
      domain: [[2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3], [2, 3, 2, 3, 2, 3, 2, 3, 2], [4, 3, 2, 3, 4, 3, 2, 3, 4]]

MontageSplits: &MontageSplits
  # VoronoiSplit: *VoronoiSplit
  CentroidPolygons: *CentroidPolygons

RegionBasedPooling: &RegionBasedPooling
  num_montage_splits:
    dist: log_uniform_int
    kwargs:
      base: 2
      a: 0  # 2^0 = 1
      b: 4  # 2^5 = 32
  normalise_region_representations:
    dist: uniform_discrete
    kwargs:
      domain: [ true ]
  share_all_pooling_modules:
    dist: uniform_discrete
    kwargs:
      domain: [ true, false ]
  num_pooling_modules: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ]  # todo
  use_cmmn_layer : [ true, false ]
  RBPDesign:
    num_designs: 1
    pooling_type: multi_cs
    pooling_module: *PoolingModules
    montage_split: *MontageSplits
    cmmn_kwargs:
      kernel_size:  # todo: what to use here?
        dist: uniform_discrete
        kwargs:
          domain: [ 64, 128, 256, 512, 1024 ]

# Interpolation
Interpolation: &Interpolation
  main_channel_system: [ Miltiadous, HatlestadHall, YulinWang, MPILemon, TDBrain, CAUEEG ]
  method: [ MNE, spline ]

Varied Numbers of Channels:
  - name: RegionBasedPooling
    kwargs: *RegionBasedPooling
  - name: Interpolation
    kwargs: *Interpolation


# -----------------
# Deep learning architectures
# TODO: I have to check the hyperparameters, of the braindecode models in particular
# -----------------
InceptionNetwork: &InceptionNetwork
  general:
    num_classes: 1
  sample:
    cnn_units:
      dist: log_uniform_int
      kwargs:
        base: 2
        a: 3
        b: 6
    depth:
      dist: n_log_uniform_int
      kwargs:
        n: 3
        base: 3
        a: 0
        b: 3

ShallowFBCSPNetMTS: &ShallowFBCSPNetMTS
  general:
    num_classes: 1
    num_time_steps: *num_time_steps
  sample:
    n_filters:
      dist: uniform_int
      kwargs:
        a: 30
        b: 51
    filter_time_length:
      dist: uniform_int
      kwargs:
        a: 15
        b: 36
    pool_time_stride:
      dist: uniform_int
      kwargs:
        a: 10
        b: 20
    drop_prob:
      dist: uniform
      kwargs:
        a: 0
        b: 0.5

Deep4NetMTS: &Deep4NetMTS
  general:
    num_classes: 1
    num_time_steps: *num_time_steps
  sample:
    n_first_filters:
      dist: uniform_int
      kwargs:
        a: 15
        b: 36
    filter_length:
      dist: uniform_int
      kwargs:
        a: 5
        b: 16
    drop_prob:
      dist: uniform
      kwargs:
        a: 0
        b: 0.5

MTS Module:
  InceptionNetwork: *InceptionNetwork
  ShallowFBCSPNetMTS: *ShallowFBCSPNetMTS
  Deep4NetMTS: *Deep4NetMTS
NormaliseInputs: [ true, false ]

PreprocessedFolder: preprocessed_2024-04-19_151355
